{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import decode_predictions, preprocess_input    \n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "import keras.backend as K\n",
    "#clear session to ensure proper runtime\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#impot the 70000 MNIST digits from sklearn datasets\n",
    "from sklearn.datasets import fetch_mldata\n",
    "mnist = fetch_mldata(\"MNIST original\")\n",
    "Xsamps = mnist.data\n",
    "ysamps = mnist.target\n",
    "X_train = Xsamps[:62500]\n",
    "y_train = ysamps[:62500]\n",
    "X_test = Xsamps[62500:]\n",
    "y_test = ysamps[62500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resaphe images from 784 to 28x28, then enlarge it to 30x30(the input size)\n",
    "from skimage.transform import resize\n",
    "def resizer(img):\n",
    "    return resize(img.reshape((28,28)),(30,30),mode='constant').flatten()\n",
    "\n",
    "#resize train and test images and change type to float32\n",
    "newX = []\n",
    "for samp in X_train:\n",
    "    newX.append(resizer(samp).astype('float32'))\n",
    "X_train = np.array(newX)\n",
    "newX = []\n",
    "for samp in X_test:\n",
    "    newX.append(resizer(samp).astype('float32'))\n",
    "X_test = np.array(newX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#divide by 255 to scale data between 0 and 1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "#change y labels from int to list index(one hot) 4 -> [0,0,0,0,1,0,0,0,0,0]\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "#set layer input and output unit amounts\n",
    "input_units = X_train.shape[1]\n",
    "output_units = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 62500 samples, validate on 7500 samples\n",
      "Epoch 1/40\n",
      " - 10s - loss: 0.2286 - acc: 0.9171 - val_loss: 0.1506 - val_acc: 0.9390\n",
      "Epoch 2/40\n",
      " - 7s - loss: 0.0976 - acc: 0.9664 - val_loss: 0.0891 - val_acc: 0.9715\n",
      "Epoch 3/40\n",
      " - 8s - loss: 0.0689 - acc: 0.9781 - val_loss: 0.0708 - val_acc: 0.9768\n",
      "Epoch 4/40\n",
      " - 9s - loss: 0.0589 - acc: 0.9810 - val_loss: 0.0640 - val_acc: 0.9789\n",
      "Epoch 5/40\n",
      " - 9s - loss: 0.0539 - acc: 0.9824 - val_loss: 0.0591 - val_acc: 0.9806\n",
      "Epoch 6/40\n",
      " - 9s - loss: 0.0508 - acc: 0.9834 - val_loss: 0.0568 - val_acc: 0.9812\n",
      "Epoch 7/40\n",
      " - 8s - loss: 0.0484 - acc: 0.9841 - val_loss: 0.0547 - val_acc: 0.9815\n",
      "Epoch 8/40\n",
      " - 8s - loss: 0.0464 - acc: 0.9848 - val_loss: 0.0521 - val_acc: 0.9825\n",
      "Epoch 9/40\n",
      " - 8s - loss: 0.0447 - acc: 0.9854 - val_loss: 0.0509 - val_acc: 0.9830\n",
      "Epoch 10/40\n",
      " - 8s - loss: 0.0431 - acc: 0.9859 - val_loss: 0.0495 - val_acc: 0.9835\n",
      "Epoch 11/40\n",
      " - 9s - loss: 0.0416 - acc: 0.9865 - val_loss: 0.0480 - val_acc: 0.9841\n",
      "Epoch 12/40\n",
      " - 9s - loss: 0.0400 - acc: 0.9870 - val_loss: 0.0459 - val_acc: 0.9847\n",
      "Epoch 13/40\n",
      " - 9s - loss: 0.0386 - acc: 0.9875 - val_loss: 0.0448 - val_acc: 0.9851\n",
      "Epoch 14/40\n",
      " - 9s - loss: 0.0372 - acc: 0.9879 - val_loss: 0.0435 - val_acc: 0.9854\n",
      "Epoch 15/40\n",
      " - 7s - loss: 0.0358 - acc: 0.9885 - val_loss: 0.0414 - val_acc: 0.9861\n",
      "Epoch 16/40\n",
      " - 7s - loss: 0.0345 - acc: 0.9889 - val_loss: 0.0405 - val_acc: 0.9865\n",
      "Epoch 17/40\n",
      " - 7s - loss: 0.0332 - acc: 0.9893 - val_loss: 0.0394 - val_acc: 0.9868\n",
      "Epoch 18/40\n",
      " - 7s - loss: 0.0320 - acc: 0.9898 - val_loss: 0.0375 - val_acc: 0.9874\n",
      "Epoch 19/40\n",
      " - 7s - loss: 0.0308 - acc: 0.9902 - val_loss: 0.0362 - val_acc: 0.9879\n",
      "Epoch 20/40\n",
      " - 7s - loss: 0.0298 - acc: 0.9905 - val_loss: 0.0349 - val_acc: 0.9883\n",
      "Epoch 21/40\n",
      " - 8s - loss: 0.0288 - acc: 0.9909 - val_loss: 0.0344 - val_acc: 0.9885\n",
      "Epoch 22/40\n",
      " - 8s - loss: 0.0277 - acc: 0.9912 - val_loss: 0.0329 - val_acc: 0.9891\n",
      "Epoch 23/40\n",
      " - 7s - loss: 0.0268 - acc: 0.9915 - val_loss: 0.0327 - val_acc: 0.9889\n",
      "Epoch 24/40\n",
      " - 8s - loss: 0.0259 - acc: 0.9918 - val_loss: 0.0311 - val_acc: 0.9895\n",
      "Epoch 25/40\n",
      " - 8s - loss: 0.0251 - acc: 0.9921 - val_loss: 0.0303 - val_acc: 0.9897\n",
      "Epoch 26/40\n",
      " - 8s - loss: 0.0244 - acc: 0.9923 - val_loss: 0.0300 - val_acc: 0.9899\n",
      "Epoch 27/40\n",
      " - 8s - loss: 0.0236 - acc: 0.9925 - val_loss: 0.0289 - val_acc: 0.9904\n",
      "Epoch 28/40\n",
      " - 8s - loss: 0.0229 - acc: 0.9928 - val_loss: 0.0280 - val_acc: 0.9905\n",
      "Epoch 29/40\n",
      " - 8s - loss: 0.0222 - acc: 0.9930 - val_loss: 0.0277 - val_acc: 0.9907\n",
      "Epoch 30/40\n",
      " - 8s - loss: 0.0215 - acc: 0.9932 - val_loss: 0.0267 - val_acc: 0.9910\n",
      "Epoch 31/40\n",
      " - 8s - loss: 0.0209 - acc: 0.9934 - val_loss: 0.0263 - val_acc: 0.9913\n",
      "Epoch 32/40\n",
      " - 8s - loss: 0.0203 - acc: 0.9937 - val_loss: 0.0252 - val_acc: 0.9916\n",
      "Epoch 33/40\n",
      " - 8s - loss: 0.0196 - acc: 0.9938 - val_loss: 0.0252 - val_acc: 0.9916\n",
      "Epoch 34/40\n",
      " - 8s - loss: 0.0191 - acc: 0.9940 - val_loss: 0.0242 - val_acc: 0.9919\n",
      "Epoch 35/40\n",
      " - 8s - loss: 0.0186 - acc: 0.9942 - val_loss: 0.0243 - val_acc: 0.9918\n",
      "Epoch 36/40\n",
      " - 8s - loss: 0.0181 - acc: 0.9944 - val_loss: 0.0232 - val_acc: 0.9923\n",
      "Epoch 37/40\n",
      " - 8s - loss: 0.0176 - acc: 0.9945 - val_loss: 0.0232 - val_acc: 0.9922\n",
      "Epoch 38/40\n",
      " - 8s - loss: 0.0171 - acc: 0.9946 - val_loss: 0.0229 - val_acc: 0.9922\n",
      "Epoch 39/40\n",
      " - 8s - loss: 0.0167 - acc: 0.9948 - val_loss: 0.0224 - val_acc: 0.9925\n",
      "Epoch 40/40\n",
      " - 8s - loss: 0.0163 - acc: 0.9949 - val_loss: 0.0223 - val_acc: 0.9926\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xc48ebbb748>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#basic neural network model with adam optimezer, using binary_crossentropy with a relu input layer and a softmax output layer\n",
    "#using binary_crossentropy because it yields a higher accuracy than categorical_crossentropy(~99% vs ~95%)\n",
    "model = Sequential()\n",
    "model.add(Dense(input_units, input_dim=input_units, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(output_units, kernel_initializer='normal', activation='softmax'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=40, batch_size=250, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model to be imported by view\n",
    "model.save(\"numeric_data.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
